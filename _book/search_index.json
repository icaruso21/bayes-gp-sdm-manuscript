[["index.html", "Bayesian Inference for Species Distribution Modelling with Gaussian Processes Isaac William Caruso Chapter 1 Probability, Bayes’ theorem, and Bayesian inference 1.1 Random Variables 1.2 Cumulative Distribution Functions 1.3 Probability Mass and Density Functions 1.4 Bayes’ Theorem 1.5 Bayesian Inference", " Bayesian Inference for Species Distribution Modelling with Gaussian Processes Isaac William Caruso Amherst College Department of Computer Science 2021-03-30 Chapter 1 Probability, Bayes’ theorem, and Bayesian inference The objective of this chapter is to provide an introduction and brief summary of the probability terms and concepts necessary for understanding and approaching Bayesian inference. Simply put, Bayesian inference is a statistical technique for iteratively updating a probability quantity of interest upon the observation of data. Specifically, the statistical technique Bayesian inference relies on is known as Bayes’ theorem and the probability quantity of interest is most often a probability density function, though in introductory examples is oftentimes a single value. Before embarking on this exposition of Bayesian statistics, one must first gain a basic appreciation for a few key elements of probability theory which will provide us with the foundational terms to discuss Bayesian inference and its applications in the broad field of machine learning—random variables and probability functions. 1.1 Random Variables Imagine for a moment you are tossing a coin. There are many experiments you could perform by tossing a coin, but for the sake of simplicity let us consider our quantity of interest to be the number of times our coin lands on a tails. It is clear that the number of tails, the outcome of our experiment, is dependent on the eventual realization of some random (stochastic) process, or at the very least not clearly deterministic. In countless scenarios like the coin toss experiment, random variables provide a convenient and uniform terminology for discussing sample spaces and their connection to some sequence of observations that is the data. In essence, a random variable is a variable whose value is dependent on the outcome(s) of a stochastic phenomenon. A random variable is commonly expressed as \\(X\\), and a realized value of \\(X\\) is \\(x\\). In the canonical example of tossing a coin, where the data is some sequence of coin tosses \\([H, T, T, …]\\), we could define a random variable \\(X\\) to be the number of tails. In this toy example, as noted above, the realized value of \\(X\\), is dependent on the outcome(s) of a random event—a coin toss. In the case of tossing a coin twice consecutively, \\(X\\)—the number of tails observations—has three possible realized states, \\(x\\), depending on the outcome of this stochastic experiment: \\(x = 0\\), \\(x = 1\\), or \\(x = 2\\). Additionally, assuming the coin is a fair coin the probability that our random variable \\(X\\) is realized as \\(x\\), some real number of tails, can be assigned to each possible overall outcome of this coin toss experiment as such: Table 1.1: P(X = x) for two tosses x P(X = x) 0 0.25 1 0.50 2 0.25 In reality, this is an example of a specific type of random variable known as a discrete random variable. Discrete random variables can, as their name implies, only assume discrete values. To the contrary, continuous random variables and mixed random variables are useful for describing sample spaces with continuous and mixed outcomes, respectively. For example, a continuous random variable may be used to describe an experiment measuring blossoming heights of flowers, where the data is a sequence of observations of heights at which different flowers blossomed. In this case, the outcome of our blossoming experiment is an infinite number of real values that is properly represented in a continuous random variable. 1.2 Cumulative Distribution Functions The concept of a distribution follows intuitively from our previous discussion of random variables. In the previous example we represented the probability of various outcomes of a coin toss experiment in a tabular format. Another way to represent this distribution of probabilities is as a cumulative distribution function: Definition 1.1 (Cumulative distribution function ‘CDF’) The cumulative distribution function is defined as a function where \\(F_{X}\\in[0, 1]\\): \\[F_{X}(x)=P(X≤x)\\] As the name implies, the cumulative distribution function simply represents the probability that a random variable \\(X\\) is realized to be less than or equal to \\(x\\) for each possible input value of \\(x\\). Figure 1.1 depicts a graphical representation of the CDF for our coin tossing experiment. Figure 1.1: CDF for tossing a coin twice (from All of Stats, should I make my own?) Here, for every value of \\(x\\)—the number of tails in two coin tosses—the probability that \\(X\\) is equal to or less than this value is represented. In this discrete example, we see that our CDF is represented by several non-decreasing discrete lines defined for all \\(x\\). In the example of a continuous random variable, this function is a continuous, non-decreasing distribution also defined for all \\(x\\). 1.3 Probability Mass and Density Functions Now that we have a basic understanding of random variables and their association with the CDF, we can begin discussing probability functions for both continuous and discrete random variables. Broadly speaking, the probability mass function and probability density function are two methods for calculating a probability over a sample space, which find their use with discrete and continuous random variables respectively. In the discrete setting, a probability mass function yields the probability of an outcome for every possible outcome in any given discrete schema. To reiterate the previous discussion of discrete versus continuous random variables, a random variable \\(X\\) is considered discrete “if it takes countably many values \\(\\{x_{1}, x_{2}, …\\}\\)” (Wasserman 2004). In this case, a definition for the probability mass function follows: Definition 1.2 (Probability mass function ‘PMF’) The probability function for a discrete random variable \\(X\\)—the probability mass function for \\(X\\)—is defined as a function \\[F_{X}(x)=P(X=x)\\] Here, the PMF has a few key attributes. Namely \\(P(X=x)&gt;0\\) for every \\(x\\) in the sample space of \\(X (x \\in S_{X})\\), and \\(\\sum_{x \\in S_{X}}f(x)=1\\). With these features in mind, the probability mass function of \\(X\\) follows logically from the cumulative distribution function of \\(X\\) insofar as the CDF is the sum of the PMF for all \\(x_{i}≤x\\). This relationship in the discrete scenario between the PMF and CDF can be expressed formally as: \\[F_{X}(x)=P(X≤x)=\\sum_{x_i≤x}f_{X}(x_{i})\\] In the continuous setting where these attributes no longer hold, a probability density function (PDF) is instead used to represent probability of \\(x\\) for all \\(x \\in S_X\\). In the case where the random variable \\(X\\) is continuous, a PDF is defined as follows: Definition 1.3 (Probability density function ‘PDF’) The probability function for a continuous random variable \\(X\\)—the probability density function for \\(X\\)—is defined as a function \\(f(x)\\) where \\(a\\) and \\(b\\) are two real numbers and every \\(a ≤ b\\), so \\[P(a&lt;X&lt;b)=\\int_{a}^{b}f_X(x)dx\\] In other words, the probability that the realized value \\(x\\) of our continuous random variable \\(X\\) is between two numbers \\(a\\) and \\(b\\) is equal to the integral of the probability density function of \\(x\\) from \\(x = a\\) to \\(x = b\\). This formalization of the PDF \\(f_X(x)\\) allows a natural comparison to be drawn to the CDF \\(F_X(x)\\) of a continuous random variable \\(X\\), that is: \\[F_X(x)=\\int_{-\\infty}^{x}f_X(x)dx\\] Specifically, this implies that \\(F&#39;_X(x)=f_X(x)\\) for all differentiable points in \\(F_X\\). In plain English this signifies that the derivative of the CDF is the PDF, in all cases involving a continuous random variable. Probability density and mass functions come in a wide variety of forms, each with their own properties and methodologies for defining their shape and characteristics. Some are useful for defining binary data, others are useful for defining arbitrarily large sample spaces with any number of localized concentrations of density. Still others boast properties, such as being closed under conditioning and marginalization, that make them useful for specific statistical applications. Figure 1.2 displays some of the most common continuous and discrete probability distributions. Figure 1.2: Common probability distributions More text now (Kotta et al. 2019) 1.4 Bayes’ Theorem 1.5 Bayesian Inference "],["approximation-algorithms-for-inference-on-complex-systems.html", "Chapter 2 Approximation algorithms for inference on complex systems", " Chapter 2 Approximation algorithms for inference on complex systems "],["modern-bayesian-inference-with-stan.html", "Chapter 3 Modern Bayesian inference with STAN", " Chapter 3 Modern Bayesian inference with STAN "],["bayesian-applications-in-biology-hybrid-species-distribution-modelling-with-gaussian-processes.html", "Chapter 4 Bayesian applications in Biology: Hybrid species distribution modelling with gaussian processes", " Chapter 4 Bayesian applications in Biology: Hybrid species distribution modelling with gaussian processes Kotta, Jonne, Jarno Vanhatalo, Holger Jänes, Helen Orav-Kotta, Luca Rugiu, Veijo Jormalainen, Ivo Bobsien, et al. 2019. “Integrating Experimental and Distribution Data to Predict Future Species Patterns.” Scientific Reports 9 (December): 1–14. https://doi.org/10.1038/s41598-018-38416-3. Wasserman, Larry. 2004. All of Statistics. Springer. "]]
